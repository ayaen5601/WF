{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Mjbb0HzlHKk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whisper  = pipeline(\"automatic-speech-recognition\",\n",
        "                    \"openai/whisper-large-v2\")\n",
        "                    # device=\"cuda:0\") # if you don't have GPU, remove this argument"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRkxB4ovlMT-",
        "outputId": "490f855b-5064-49df-89af-1781b8df221b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = whisper(\"Sample_audio_for_Whisper.mp3\",\n",
        "                        chunk_length_s=30)\n",
        "print(transcription[\"text\"][:500])\n",
        "# Optimizing Performance with Chunk and Stride Length, https://huggingface.co/blog/asr-chunking\n",
        "# transcription = whisper(\"<LONGER AUDIO FILE.mp3>\",\n",
        "#                     chunk_length_s=30,\n",
        "#                     stride_length_s=5,\n",
        "#                     batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVZnECCWlMQT",
        "outputId": "c996d155-2dcc-44b9-f234-144927ffcc23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " WISPR is a transformer-based encoder-decoder model, also referred to as a sequence-to-sequence model. It was trained on 680k hours of labelled speech data, annotated using large-scale weak supervision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SprZ9jDrlMNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "526Ur5gZlLu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bsmjqrWlLrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}